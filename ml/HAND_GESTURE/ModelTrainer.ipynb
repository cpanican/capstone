{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"]}],"source":"import tensorflow as tf\nimport tflearn\nfrom tflearn.layers.conv import conv_2d,max_pool_2d\nfrom tflearn.layers.core import input_data,dropout,fully_connected\nfrom tflearn.layers.estimator import regression\nimport numpy as np\nimport cv2\nfrom sklearn.utils import shuffle"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"loadedImages = []\n#Load Images from Swing\nfor i in range(0, 1000):\n    image = cv2.imread('Dataset/SwingImages/swing_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images From Palm\nfor i in range(0, 1000):\n    image = cv2.imread('Dataset/PalmImages/palm_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n    \n#Load Images From Fist\nfor i in range(0, 1000):\n    image = cv2.imread('Dataset/FistImages/fist_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images From Point\nfor i in range(0, 1000):\n    image = cv2.imread('Dataset/PointImages/point_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    loadedImages.append(gray_image.reshape(89, 100, 1))\n"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"# Create OutputVector\n\noutputVectors = []\nfor i in range(0, 1000):\n    outputVectors.append([1, 0, 0, 0])\n\nfor i in range(0, 1000):\n    outputVectors.append([0, 1, 0, 0])\n\nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 1, 0])\n    \nfor i in range(0, 1000):\n    outputVectors.append([0, 0, 0, 1])"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"testImages = []\n\n#Load Images for swing\nfor i in range(0, 100):\n    image = cv2.imread('Dataset/SwingTest/swing_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images for Palm\nfor i in range(0, 100):\n    image = cv2.imread('Dataset/PalmTest/palm_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n    \n#Load Images for Fist\nfor i in range(0, 100):\n    image = cv2.imread('Dataset/FistTest/fist_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n\n#Load Images for Point\nfor i in range(0, 100):\n    image = cv2.imread('Dataset/PointTest/point_' + str(i) + '.png')\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    testImages.append(gray_image.reshape(89, 100, 1))\n\ntestLabels = []\n\nfor i in range(0, 100):\n    testLabels.append([1, 0, 0, 0])\n    \nfor i in range(0, 100):\n    testLabels.append([0, 1, 0, 0])\n\nfor i in range(0, 100):\n    testLabels.append([0, 0, 1, 0])\n\nfor i in range(0, 100):\n    testLabels.append([0, 0, 0, 1])"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"# Define the CNN Model\ntf.reset_default_graph()\nconvnet=input_data(shape=[None,89,100,1],name='input')\nconvnet=conv_2d(convnet,32,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\nconvnet=conv_2d(convnet,64,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,128,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,256,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,256,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,128,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=conv_2d(convnet,64,2,activation='relu')\nconvnet=max_pool_2d(convnet,2)\n\nconvnet=fully_connected(convnet,1000,activation='relu')\nconvnet=dropout(convnet,0.75)\n\n# second parameter in fully_connected is number of classes\nconvnet=fully_connected(convnet,4,activation='softmax')\n\nconvnet=regression(convnet,optimizer='adam',learning_rate=0.001,loss='categorical_crossentropy',name='regression')\n\nmodel=tflearn.DNN(convnet,tensorboard_verbose=0)\n"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"# Shuffle Training Data\nloadedImages, outputVectors = shuffle(loadedImages, outputVectors, random_state=0)"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Step: 3149  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 17.703s\n","| Adam | epoch: 050 | loss: 0.00005 - acc: 1.0000 -- iter: 3968/4000\n","Training Step: 3150  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 18.980s\n","| Adam | epoch: 050 | loss: 0.00005 - acc: 1.0000 | val_loss: 0.54079 - val_acc: 0.7950 -- iter: 4000/4000\n","--\n","INFO:tensorflow:/Users/chris/projects/capstone-test/TrainedModel/GestureRecogModel.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"]}],"source":"# Train model\nmodel.fit(loadedImages, outputVectors, n_epoch=50,\n           validation_set = (testImages, testLabels),\n           snapshot_step=100, show_metric=True, run_id='convnet_coursera')\n\nmodel.save(\"TrainedModel/GestureRecogModel.tfl\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}